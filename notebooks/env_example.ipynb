{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for how to load the environments\n",
    "\n",
    "For the most part, this should just work. The one pain point is the optimal Connect 4 agent, which I may need to be recompiled and have permissions changed to allow the resulting file to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ssd004/home/keirp/Documents/esper_envs/esper_envs/samplers/trajectory_sampler.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset file found. Loading existing trajectories.\n",
      "Dataset file found. Loading existing trajectories.\n",
      "Dataset file found. Loading existing trajectories.\n"
     ]
    }
   ],
   "source": [
    "from stochastic_offline_envs.envs.offline_envs.connect_four_offline_env import ConnectFourOfflineEnv\n",
    "\n",
    "# Load the Connect 4 offline RL environment\n",
    "c4_task = ConnectFourOfflineEnv()\n",
    "\n",
    "# # Load the 2048 offline RL environment\n",
    "from stochastic_offline_envs.envs.offline_envs.tfe_offline_env import TFEOfflineEnv\n",
    "tfe_task = TFEOfflineEnv()\n",
    "\n",
    "# # Load the gambling offline RL environment\n",
    "from stochastic_offline_envs.envs.offline_envs.gambling_offline_env import GamblingOfflineEnv\n",
    "gambling_task = GamblingOfflineEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the env, we can use the env_cls property of the task\n",
    "c4_env = c4_task.env_cls()\n",
    "obs = c4_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the dataset, use the trajs property\n",
    "c4_trajs = c4_task.trajs\n",
    "\n",
    "# The traj is a named tuple with the following fields:\n",
    "# - obs: a list of observations\n",
    "# - actions: a list of actions\n",
    "# - rewards: a list of rewards\n",
    "# - infos: a list of infos\n",
    "# - policy_infos: a list of policy_infos\n",
    "# View trajectory_sampler.py for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: (84,)\n",
      "Action space: 7\n"
     ]
    }
   ],
   "source": [
    "# For Connect Four in particular, you may want to use the following env wrapper to get the board state\n",
    "from stochastic_offline_envs.envs.connect_four.connect_four_env import GridWrapper\n",
    "\n",
    "c4_env_wrapped = GridWrapper(c4_env)\n",
    "print(f'Observation space: {c4_env_wrapped.observation_space.shape}')\n",
    "print(f'Action space: {c4_env_wrapped.action_space.n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: (4, 4, 8)\n",
      "Action space: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ssd004/home/keirp/Documents/stoch_rvs/gym-2048/gym_2048/env.py:120: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  board[tile_locs] = tiles\n",
      "/scratch/ssd004/home/keirp/Documents/esper_envs/esper_envs/envs/offline_envs/tfe_offline_env.py:41: RuntimeWarning: divide by zero encountered in log2\n",
      "  log_flat_obs = np.log2(flat_obs).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Note that for 2048, the environment terminates when a 128 tile is created.\n",
    "tfe_env = tfe_task.env_cls()\n",
    "obs = tfe_env.reset()\n",
    "print(f'Observation space: {tfe_env.observation_space.shape}')\n",
    "print(f'Action space: {tfe_env.action_space.n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: (7,)\n",
      "Action space: 3\n"
     ]
    }
   ],
   "source": [
    "gambling_env = gambling_task.env_cls()\n",
    "obs = gambling_env.reset()\n",
    "print(f'Observation space: {gambling_env.observation_space.shape}')\n",
    "print(f'Action space: {gambling_env.action_space.n}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('gv2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f272fe55a377753b732a007f7e3be29c56f3182573f8738296090c33784971c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
